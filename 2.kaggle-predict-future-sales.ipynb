{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n    from itertools import product\n    for block_num in sale_train['date_block_num'].unique():\n        cur_shops = sale_train[sale_train['date_block_num']==block_num]['shop_id'].unique()\n        cur_items = sale_train[sale_train['date_block_num']==block_num]['item_id'].unique()\n        grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n    \n    index_cols = ['shop_id', 'item_id', 'date_block_num']\n    train_set = pd.DataFrame(np.vstack(grid),columns=index_cols,dtype=np.int32)\n    del grid\n    \n    # 读取测试集文件\n    test = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv')\n    test_set = test[['shop_id','item_id']].copy()\n    test_set['date_block_num']=34\n    \n    all_set=pd.concat([train_set,test_set])\n    all_set.shop_id=all_set.shop_id.astype(np.int8)\n    all_set.date_block_num=all_set.date_block_num.astype(np.int8)\n    \n    # 求取商店城市信息\n    from sklearn.preprocessing import LabelEncoder\n    shops = pd.read_csv('../input/competitive-data-science-predict-future-sales/shops.csv')\n    shops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n    shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n    shops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\n    shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n    shops = shops[['shop_id','city_code']]\n    all_set=all_set.merge(shops, on = 'shop_id', how = 'left')\n    all_set['city_code']=all_set['city_code'].astype(np.int8)\n    \n    # 将item所属类别汇入数据集网格中(数据文件给出的类别)\n    item = pd.read_csv('../input/competitive-data-science-predict-future-sales/items.csv')\n    all_set = all_set.merge(item[['item_id', 'item_category_id']], on = ['item_id'],how = 'left')\n    all_set.item_id = all_set.item_id.astype(np.int16)\n    all_set.item_category_id = all_set.item_category_id.astype(np.int8)\n    \n    # 商品的类别特征（由名字划分的类别与子类别）\n    cats = pd.read_csv('../input/competitive-data-science-predict-future-sales/item_categories.csv')\n    cats['split']= cats['item_category_name'].str.split('-')\n    cats['type'] = cats['split'].map(lambda x: x[0].strip())\n    cats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n    \n    cats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n    cats['subtype'] = cats['subtype'].map(lambda x: x.split('(')[0].strip())\n    cats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\n    cats = cats[['item_category_id','type_code', 'subtype_code']]\n    \n    all_set=all_set.merge(cats, on = 'item_category_id', how = 'left')\n    all_set['type_code']=all_set['type_code'].astype(np.int8)\n    all_set['subtype_code']=all_set['subtype_code'].astype(np.int8)\n    del shops,item,cats\n    \n    # 对sale_data文件中记录的月销售数据和产品月平均售价进行特征提取（'item_cnt_month')\n    id_cols=['shop_id', 'item_id']\n    sale_train['item_cnt_day']=sale_train['item_cnt_day'].clip(day_sala_min,day_sala_max)\n    data_tmp=sale_train[id_cols+[date_block_col]+['item_cnt_day']]\n    data_tmp=data_tmp.groupby(by=id_cols+[date_block_col])['item_cnt_day'].agg(['sum']).reset_index().rename(columns={'sum':'item_cnt_month'})\n    \n    data_tmp['item_cnt_month'] = data_tmp['item_cnt_month'].clip(0,20).astype(np.int8)\n    all_set=all_set.merge(data_tmp,on=['shop_id','item_id','date_block_num'],how='left').fillna(0)\n    \n    # 提取商品的价格均值特征\n    data_tmp = sale_train.groupby(['item_id']).agg({'item_price': ['mean']})\n    data_tmp.columns = ['item_price_mean']\n    data_tmp.reset_index(inplace=True)\n    \n    all_set = pd.merge(all_set, data_tmp, on=['item_id'], how='left')\n    all_set['item_price_mean'] = all_set['item_price_mean'].astype(np.float16)\n    \n    # 提取商品价格月均值特征\n    data_tmp = sale_train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\n    data_tmp.columns = ['item_price_mean_month']\n    data_tmp.reset_index(inplace=True)\n    \n    all_set = pd.merge(all_set, data_tmp, on=['date_block_num','item_id'], how='left')\n    all_set['item_price_mean_month'] = all_set['item_price_mean_month'].astype(np.float16)\n    \n    # 求价格相对平均价格的浮动值, 偏置月份为[1,2,3,4,5,6]\n    lags = [1,2,3,4,5,6]\n    all_set = lag_feature(all_set, lags, ['item_price_mean_month'])\n    for i in lags:  \n        all_set['item_price_delta_month_pre_'+str(i)] = \\\n            (all_set['item_price_mean_month_pre_'+str(i)] - all_set['item_price_mean']) / all_set['item_price_mean']\n    \n    #求最近的价格浮动值（如果上一个月内该产品没有被销售,则用上上一个月的价格浮动值代替）\n    all_set['item_price_delta_month']=all_set['item_price_delta_month_pre_1'].copy()\n    for i in [2,3,4,5]:   \n        all_set.loc[all_set['item_price_delta_month'].isna(),'item_price_delta_month'] \\\n            =all_set.loc[all_set['item_price_delta_month'].isna(),'item_price_delta_month_pre_'+str(i)]\n    all_set=all_set.fillna(0)\n    \n    # 提取营业额特征['revenue']=['item_price']*['item_cnt_day']\n    sale_train['revenue']=sale_train['item_price']*sale_train['item_cnt_day'] \n    group = sale_train.groupby(['date_block_num','shop_id']).agg({'revenue':['sum']})\n    group.columns = ['shop_id_revenue_month']\n    group.reset_index(inplace=True)\n    \n    all_set = pd.merge(all_set, group, on=['date_block_num','shop_id'], how='left')\n    all_set['shop_id_revenue_month'] = all_set['shop_id_revenue_month'].astype(np.float32)\n    \n    group = group.groupby(['shop_id']).agg({'shop_id_revenue_month': ['mean']})\n    group.columns = ['shop_id_revenue']\n    group.reset_index(inplace=True)\n    \n    all_set = pd.merge(all_set, group, on=['shop_id'], how='left')\n    all_set['shop_id_revenue'] = all_set['shop_id_revenue'].astype(np.float32)\n    \n    all_set['revenue_float_month'] = (all_set['shop_id_revenue_month'] - all_set['shop_id_revenue']) / all_set['shop_id_revenue']\n    all_set['revenue_float_month'] = all_set['revenue_float_month'].astype(np.float16)\n    all_set = lag_feature(all_set,[1], ['revenue_float_month'])\n    all_set.drop(['shop_id_revenue','shop_id_revenue_month','revenue_float_month'], axis=1, inplace=True)\n    \n    # 提取日期特征('month', 'year','days_of_month')\n    sale_train['date'] = pd.to_datetime(sale_train['date'], format = '%d.%m.%Y')\n    data_tmp=sale_train[['shop_id','date', 'date_block_num']].drop_duplicates()\n\n    data_tmp['day']=data_tmp['date'].dt.day\n    data_tmp=data_tmp[['shop_id','date_block_num','day']]\n    data_tmp=data_tmp.groupby(['shop_id','date_block_num']).agg(['min','max']).reset_index()\n    data_tmp['days_of_month']=data_tmp['day','max']+1-data_tmp['day','min']\n    data_tmp=data_tmp[['shop_id','date_block_num','days_of_month']]\n    data_tmp.columns=data_tmp.columns.droplevel(1)\n    \n    all_set=all_set.merge(data_tmp,on=['shop_id','date_block_num'],how='left')\n    all_set.loc[all_set.date_block_num==34,'days_of_month']=30\n    all_set.days_of_month=all_set.days_of_month.astype(np.int8)\n    \n    all_set['month']=all_set[date_block_col]%12\n    all_set['month']=all_set['month'].astype(np.int8)\n    \n    all_set['year']=(all_set[date_block_col]/12)\n    all_set['year']=all_set['year'].astype(np.int8)\n    \n    return all_set\n\n# ************************************ 特征工程 *****************************\ndef data_feature_extract(all_set):\n    train_data = all_set[all_set['date_block_num']<=33]\n    \n    # 提取shop_code特征\n    data_tmp=train_data.groupby(by=['shop_id','date_block_num'])['item_cnt_month'].sum().reset_index()\n    data_tmp=data_tmp.groupby(by=['shop_id'])['item_cnt_month'].mean().reset_index().rename(columns={'item_cnt_month':'shop_code'})\n    data_tmp['shop_code']=((data_tmp.shop_code/50)+0.5).astype(np.int16).clip(0,200).map(lambda x:x if x<=70 else 70+(x-70)/10).astype(np.int16)# 70这个值是由盒形图决定取的~\n    train_data=train_data.merge(data_tmp,on=['shop_id'],how='left')\n    all_set=all_set.merge(data_tmp,on=['shop_id'],how='left')\n    \n    # 提取item_category_code特征\n    data_tmp=train_data.groupby(by=['item_category_id','date_block_num'])['item_cnt_month'].sum().reset_index()\n    data_tmp=data_tmp.groupby(by=['item_category_id'])['item_cnt_month'].mean().reset_index().rename(columns={'item_cnt_month':'item_category_code'})\n    data_tmp['item_category_code']=(data_tmp.item_category_code.clip(0,2000)/10+0.5).map(lambda x:x if x<=100 else 100+(x-100)/10).astype(np.int16)\n    train_data=train_data.merge(data_tmp,on=['item_category_id'],how='left')\n    all_set=all_set.merge(data_tmp,on=['item_category_id'],how='left')\n    \n    # 提取item_code特征\n    data_tmp=train_data.groupby(by=['item_id','date_block_num'])['item_cnt_month'].sum().reset_index()\n    data_tmp=data_tmp.groupby(by=['item_id'])['item_cnt_month'].mean().reset_index().rename(columns={'item_cnt_month':'item_code'})\n    data_tmp['item_code']=(data_tmp['item_code']+0.5).clip(0,200).astype(np.int16).map(lambda x:x if x<=25 else 25+(x-25)/10).astype(np.int16)\n    train_data=train_data.merge(data_tmp,on=['item_id'],how='left')\n    all_set=all_set.merge(data_tmp,on=['item_id'],how='left')\n    \n    # 用['item_id','type_code','subtype_code']下的月均值对['item_code']缺失项进行补足\n    data_tmp=all_set.loc[all_set.date_block_num<34,['item_id','type_code','subtype_code','item_code']]\n    \n    data_tmp=data_tmp.groupby(['type_code','subtype_code'])['item_code'].median().reset_index().rename(columns={'item_code':'item_code_fix'})\n    all_set.loc[all_set.item_code.isna(),'item_code']=all_set.loc[all_set.item_code.isna()]\\\n        .merge(data_tmp,on=['type_code','subtype_code'],how='left').item_code_fix.values\n    \n    # (shop_id、item_id)、(item_id)中上一次销售出去的月份\n    # shop_item_last_sale=pd.DataFrame()\n    # item_id_last_sale=pd.DataFrame()\n    all_set['shop_item_last_sale'] = NaN\n    all_set['item_id_last_sale'] = NaN\n    for i in range(0,35):\n        data_tmp=all_set.loc[(all_set.date_block_num<i)&(all_set.item_cnt_month>0),['shop_id','item_id','date_block_num']].drop_duplicates()\n        data_tmp=data_tmp.groupby(by=['shop_id','item_id'])['date_block_num'].max().reset_index().rename(columns={'date_block_num':'shop_item_last_sale'})\n        data_tmp['shop_item_last_sale']=i-data_tmp['shop_item_last_sale']\n        data_tmp=all_set.loc[all_set.date_block_num==i,['shop_id','item_id']].merge(data_tmp,on=['shop_id','item_id'],how='left')\n        # shop_item_last_sale=pd.concat([shop_item_last_sale, data_tmp['shop_item_last_sale']], axis = 0)\n        all_set.loc[all_set.date_block_num==i,'shop_item_last_sale']=data_tmp['shop_item_last_sale'].values\n        \n        data_tmp=all_set.loc[(all_set.date_block_num<i)&(all_set.item_cnt_month>0),['item_id','date_block_num']].drop_duplicates()\n        data_tmp=data_tmp.groupby(by=['item_id'])['date_block_num'].max().reset_index().rename(columns={'date_block_num':'item_id_last_sale'})\n        data_tmp['item_id_last_sale']=i-data_tmp['item_id_last_sale']\n        data_tmp=all_set.loc[all_set.date_block_num==i,['item_id']].merge(data_tmp,on=['item_id'],how='left')\n        # item_id_last_sale=pd.concat([item_id_last_sale, data_tmp['item_id_last_sale']], axis = 0)\n        all_set.loc[all_set.date_block_num==i,'item_id_last_sale']=data_tmp['item_id_last_sale'].values\n    \n    \n    #all_set['shop_item_last_sale'] = shop_item_last_sale[0]\n    all_set['shop_item_last_sale'] = all_set['shop_item_last_sale'].fillna(-1)\n    all_set['shop_item_last_sale'] = all_set['shop_item_last_sale'].astype(np.int8)\n    \n    # all_set=pd.concat([all_set, item_id_last_sale], axis = 1)\n    \n    #all_set['item_id_last_sale'] = item_id_last_sale[0]\n    all_set['item_id_last_sale'] = all_set['item_id_last_sale'].fillna(-1)\n    all_set['item_id_last_sale'] = all_set['item_id_last_sale'].astype(np.int8)  \n    \n    # shop_id、item_id下的第一次销售月份距离当前月份值\n    all_set['shop_item_first_sale'] = all_set['date_block_num'] - all_set.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n    all_set['item_id_first_sale'] = all_set['date_block_num'] - all_set.groupby('item_id')['date_block_num'].transform('min')\n    \n    # 求['shop_id','item_category_id','item_id','city_code','type_code','subtype_code']下各均值特征\n    global_mean =  train_data['item_cnt_month'].mean()\n    corrcoefs = pd.DataFrame(columns = ['Cor'])\n    y_tr = train_data['item_cnt_month'].values\n    colofCode=['shop_id','item_category_id','item_id','city_code','type_code','subtype_code']\n    for col in colofCode:\n        col_tr=train_data[[col]+['item_cnt_month']]\n        cumsum = col_tr.groupby(col)['item_cnt_month'].cumsum() - col_tr['item_cnt_month']\n        sumcnt = col_tr.groupby(col).cumcount()+1\n        col_tr[col + '_cnt_month_mean'] = cumsum / sumcnt\n        col_tr[col + '_cnt_month_mean'].fillna(global_mean, inplace=True)\n        corrcoefs.loc[col + '_cnt_month_mean'] = np.corrcoef(y_tr, col_tr[col + '_cnt_month_mean'])[0][1]\n        train_data = pd.concat([train_data, col_tr[col + '_cnt_month_mean']], axis = 1)\n        print(corrcoefs.sort_values('Cor'))\n    \n    train_data=downcast_dtypes(train_data)\n    feature_col=[col for col in train_data.columns if '_cnt_month_mean' in col]\n    \n    all_set=all_set.merge(train_data[id_cols+[date_block_col]+feature_col],on=id_cols+[date_block_col], how = 'left')\n    \n    del data_tmp\n\n    # 提取当前月的前第一个月、前第二个月、前第三个月、前第四个月、前年该月的销量各特征作为特征\n    #shift_range = [1,2,3,6,12]        # 下一个月、两个月、三个月、四个月和下一年\n    \n    \n    all_set=all_set[all_set.date_block_num>=12]\n    # 求['shop_id_cnt_month_mean'、'item_id_cnt_month_mean'、'item_cnt_month']的[1,2,3,6,12]偏置\n    cols_to_rename=[\n                    'shop_id_cnt_month_mean',\n                    'item_id_cnt_month_mean',\n                    'item_cnt_month'\n                    ]\n    shift_range = [1,2,3,6,12]\n    all_set=lag_feature(all_set,shift_range,cols_to_rename)\n    # 求['shop_id_cnt_month_mean'、'item_id_cnt_month_mean'、'item_cnt_month']的[1]偏置\n    cols_to_rename=[\n                    'item_category_id_cnt_month_mean',\n                    'city_code_cnt_month_mean',\n                    'subtype_code_cnt_month_mean',\n                    'type_code_cnt_month_mean',\n                    ]\n    shift_range = [1]\n    all_set=lag_feature(all_set,shift_range,cols_to_rename)\n    \n    all_set=all_set.fillna(0)\n    all_set = downcast_dtypes(all_set)\n    return all_set\n\n# ************************************ 数据处理 *****************************\ndef date_del(data_path):\n    # 从csv文件中将数据导入到DataFrame当中,并对数据进行清洗和剔除,保留有用的数据\n    all_set=data_cleansing_integration()\n    # all_set.to_csv('%s/all_set.csv' % data_path,index=False)\n\n    # all_set=pd.read_csv('%s/all_set.csv' % data_path)\n    # 对数据集中的数据进行特征工程\n    all_set=data_feature_extract(all_set)\n    \n    shops_pred=list(all_set.loc[all_set.date_block_num==34,'shop_id'].drop_duplicates())\n    all_set=all_set.loc[all_set.shop_id.isin(shops_pred)]\n    ####################3.模型########################\n    all_set=all_set[[\n                        'shop_id', \n                        'item_id', \n                        'date_block_num', \n                        'city_code', \n                        'item_category_id',\n                        'type_code', \n                        'subtype_code', \n                        'item_cnt_month', \n                        # 'item_price_mean',\n                        # 'item_price_mean_month', \n                        # 'item_price_mean_month_pre_1',\n                        # 'item_price_mean_month_pre_2', \n                        # 'item_price_mean_month_pre_3',\n                        # 'item_price_mean_month_pre_4', \n                        # 'item_price_mean_month_pre_5',\n                        # 'item_price_mean_month_pre_6', \n                        # 'item_price_delta_month_pre_1',\n                        # 'item_price_delta_month_pre_2', \n                        # 'item_price_delta_month_pre_3',\n                        # 'item_price_delta_month_pre_4', \n                        # 'item_price_delta_month_pre_5',\n                        # 'item_price_delta_month_pre_6', \n                        'item_price_delta_month',\n                        'revenue_float_month_pre_1', \n                        'days_of_month',\n                        'month', \n                        'year',\n                        'shop_code', \n                        'item_category_code', \n                        'item_code',\n                        # 'shop_id_cnt_month_mean', \n                        # 'item_category_id_cnt_month_mean',\n                        # 'item_id_cnt_month_mean', \n                        # 'city_code_cnt_month_mean',\n                        # 'type_code_cnt_month_mean', \n                        # 'subtype_code_cnt_month_mean',\n                        'shop_id_cnt_month_mean_pre_1', \n                        'item_id_cnt_month_mean_pre_1',\n                        'item_cnt_month_pre_1', \n                        'shop_id_cnt_month_mean_pre_2',\n                        'item_id_cnt_month_mean_pre_2', \n                        'item_cnt_month_pre_2',\n                        'shop_id_cnt_month_mean_pre_3', \n                        'item_id_cnt_month_mean_pre_3',\n                        'item_cnt_month_pre_3', \n                        'shop_id_cnt_month_mean_pre_6',\n                        'item_id_cnt_month_mean_pre_6', \n                        'item_cnt_month_pre_6',\n                        'shop_id_cnt_month_mean_pre_12', \n                        'item_id_cnt_month_mean_pre_12',\n                        'item_cnt_month_pre_12', \n                        'item_category_id_cnt_month_mean_pre_1',\n                        'city_code_cnt_month_mean_pre_1', \n                        'subtype_code_cnt_month_mean_pre_1',\n                        'type_code_cnt_month_mean_pre_1',\n                        'shop_item_first_sale',\n                        'shop_item_last_sale',\n                        'item_id_first_sale',\n                        'item_id_last_sale'\n                    ]]\n    \n    num_first_level_models=3\n    meta_size=21\n    slice_start = 0\n    \n    Target = 'item_cnt_month'\n    \n    meta_months_data=range(12+meta_size,35)       # \n    mask = all_set[date_block_col].isin(meta_months_data)\n    y_all_level2 = all_set[Target][mask].values\n    X_all_level2 = np.zeros([y_all_level2.shape[0], num_first_level_models])\n    \n    pre_cols = [col for col in all_set.columns if '_pre_' in col]\n    others_cols=['item_category_id','month', 'year','days_of_month','item_price_delta_month',\n                 'shop_item_first_sale','shop_item_last_sale','item_id_first_sale','item_id_last_sale']\n    id_code=['shop_code', 'item_category_code', 'item_code','city_code','type_code','subtype_code']\n    from sklearn.metrics import mean_squared_error\n    from math import sqrt\n    for cur_block_num in tqdm(meta_months_data):\n        # 3.0 建立训练集和测试集\n        mask=all_set['date_block_num'].isin(range(cur_block_num-meta_size,cur_block_num))\n        train_set=all_set[mask][id_cols+id_code+pre_cols+others_cols].copy()\n        train_value=all_set[mask][Target].copy()\n        test_set=all_set[all_set[date_block_col]==cur_block_num][id_cols+id_code+pre_cols+others_cols].copy()\n        test_value=all_set[all_set[date_block_col]==cur_block_num][Target].copy()\n        \n        preds=[]\n        # 3.1 lightgbm模型\n        import lightgbm as lgb\n        lgb_params = {\n                      'feature_fraction': 0.9,        # 每次迭代的时候随机选择特征的比例，默认为1，训练前选好\n                      'metric': 'rmse',                # root square loss(平方根损失）\n                      'nthread':3,                    # LightGBM 的线程数\n                      'min_data_in_leaf': 2**2,        # 一个叶子上数据的最小数量. 可以用来处理过拟合\n                      'bagging_fraction': 0.75,        # 类似于 feature_fraction, 但是它在训练时选特征\n                      'learning_rate': 0.02,        # 学习率\n                      'objective': 'rmse',            # regression_l2, L2 loss, alias=regression, mean_squared_error, mse\n                      # 'bagging_seed': 2**7,            # bagging 随机数种子\n                      'num_leaves': 2**11,            # 一棵树上的叶子数\n                      'bagging_freq':1,                # bagging 的频率, 0 意味着禁用 bagging. k意味着每 k次迭代执行bagging\n                      'verbose':1                    # verbose: 详细信息模式，0 或者 1 \n                      }\n        estimator = lgb.train(lgb_params, lgb.Dataset(train_set, label=train_value), 500)\n        pred_test = estimator.predict(test_set)\n        # pred_train = estimator.predict(train_set)\n        \n        preds.append(pred_test)\n        \n        # print('Train RMSE for %s is %f' % ('lightgbm', sqrt(mean_squared_error(train_value, pred_train.clip(0,20)))))\n        print('Test RMSE for %s is %f' % ('lightgbm', sqrt(mean_squared_error(test_value.values.clip(0,20), pred_test.clip(0,20)))))\n        \n        slice_end = slice_start + test_set.shape[0]\n        X_all_level2[ slice_start : slice_end , :] = np.c_[preds].transpose()        # transpose用于转置的\n        slice_start = slice_end\n        \n        print(\"运行时长为：%dmin%ds\\t 完成一轮训练\"%((time.time()-start_time)/60,(time.time()-start_time)%60))\n        \n        # plt.figure()\n        # plt.plot(pred_test.clip(0,20))\n        # plt.title(\"just pre\")\n        # plt.figure()\n        # plt.plot(test_value.values.clip(0,20))\n        # plt.title(\"just test\")\n        # plt.figure()\n        # plt.plot(pred_test.clip(0,20)-test_value.values.clip(0,20))\n        # plt.title(\"just pred-test\")\n        \n        # lgb.plot_importance(estimator, max_num_features=100)\n        # plt.title(\"Featurertances\")\n        # plt.show()\n        \n    submission_path=\"../Result\"\n    submission = pd.read_csv('%s/sample_submission.csv' % data_path)\n    submission['item_cnt_month'] = pred_test.clip(0,20)\n    submission[['ID', 'item_cnt_month']].to_csv('%s/submission_Lightgvm.csv' % (submission_path), index = False)\n    \n    # 4. Ensembling -------------------------------------------------------------------\n    test_nrow = len(preds[0])        # 预测的占的长度\n    X_train_level2 = X_all_level2[ : -test_nrow, :]        # 训练集（前面预测的第27月到33月的值）test_nrow=214200\n    X_test_level2 = X_all_level2[ -test_nrow: , :]        # 测试集（前面预测的第34月值）\n    y_train_level2 = y_all_level2[ : -test_nrow]        # 训练集实际值\n    \n    # A. Second level learning model via linear regression第二层学习,模型1,使用线性回归模型\n    from sklearn.linear_model import LinearRegression\n    lr = LinearRegression()\n    lr.fit(X_train_level2, y_train_level2)\n    test_preds_lr_stacking = lr.predict(X_test_level2)\n    train_preds_lr_stacking = lr.predict(X_train_level2)\n    print('Train R-squared for %s is %f' %('train_preds_lr_stacking', sqrt(mean_squared_error(y_train_level2, train_preds_lr_stacking))))\n    \n    submission_path=\"../Result\"\n    submission = pd.read_csv('%s/sample_submission.csv' % data_path)\n    submission['item_cnt_month'] = test_preds_lr_stacking.clip(0,20)\n    submission[['ID', 'item_cnt_month']].to_csv('%s/submission_Lightgvm_use_ens.csv' % (submission_path), index = False)\n    \n    print(\"运行时长为：%dmin%ds\\t 预测完成\"%((time.time()-start_time)/60,(time.time()-start_time)%60))\n    \n    plt.figure()\n    plt.plot(pred_test.clip(0,20))\n    plt.title(\"just pre\")\n    plt.figure()\n    plt.plot(submission['item_cnt_month'])\n    plt.title(\"use_en\")\n    \n    print()\n\n\nif __name__ == '__main__':\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import warnings\n    warnings.filterwarnings('ignore')\n    \n    import pandas as pd\n    pd.set_option('display.max_rows', 99)        # 在控制台显示dataframe数据最多行数,超过后自动省略\n    pd.set_option('display.max_columns', 50)     # 在控制台显示dataframe数据最多列数,超过后自动省略\n    \n    from tqdm import tqdm\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    month_sala_min=0\n    month_sala_max=20\n    \n    import time\n    start_time = time.time()\n    \n    data_path = '../Data'\n    \n    id_cols=['shop_id', 'item_id']\n    date_block_col='date_block_num'\n    date_del(data_path)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"},"execution_count":null,"outputs":[]}]}
